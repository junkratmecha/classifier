{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ライブラリインポート**"
      ],
      "metadata": {
        "id": "vs9_BNnSqyfv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDU4Z7uVk8v-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "device と seed設定"
      ],
      "metadata": {
        "id": "RB20lCDW-15n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device\", device)\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeL54IvkG9tn",
        "outputId": "5a66c65d-83d4-4490-bb37-d979ec181a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fdf0ed40790>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ハイパーパラメーター"
      ],
      "metadata": {
        "id": "glPxG-QbCe8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "num_classes = 100\n",
        "epochs = 150"
      ],
      "metadata": {
        "id": "YJSnJ3qLHIFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **データセット**"
      ],
      "metadata": {
        "id": "i54M-tH5qtrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "\n",
        "x_train = np.moveaxis(x_train, [3, 1, 2], [1, 2, 3]).astype('float32')\n",
        "x_test = np.moveaxis(x_test, [3, 1, 2], [1, 2, 3]).astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = y_train.reshape(-1).astype('long')\n",
        "y_test = y_test.reshape(-1).astype('long')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYfaso1dp01O",
        "outputId": "e102b072-932c-4b4a-dde3-c26062837c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 3s 0us/step\n",
            "169017344/169001437 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpyにセット"
      ],
      "metadata": {
        "id": "VhDU1ZBZCv6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = data.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
        "ds_test  = data.TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))"
      ],
      "metadata": {
        "id": "kd60ullfHRnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "データローダー作成"
      ],
      "metadata": {
        "id": "cdNuJN40C1GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_train = data.DataLoader(dataset=ds_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "dataloader_test = data.DataLoader(dataset=ds_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "3k3cf5HdHYVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **モデル作成**"
      ],
      "metadata": {
        "id": "9CEsx3ipvFnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cifar100Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Cifar100Model, self).__init__()\n",
        "        self.conv11 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv12 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv22 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, num_classes)\n",
        "\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.25)\n",
        "        self.dropout3 = nn.Dropout2d(0.5)\n",
        "        self.dropout4 = nn.Dropout2d(0.5)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv11(x))\n",
        "        x = F.relu(self.conv12(x))\n",
        "        x = F.max_pool2d(x, (2, 2))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.conv21(x))\n",
        "        x = F.relu(self.conv22(x))\n",
        "        x = F.max_pool2d(x, (2, 2))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout3(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout4(x)\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "yYApcjvWukfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "確認"
      ],
      "metadata": {
        "id": "p1S4fXXWvJP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Cifar100Model().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "Ccwp-XlruwAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "304abb41-de23-4f1c-af2a-4deccb272c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cifar100Model(\n",
            "  (conv11): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv21): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv22): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=100, bias=True)\n",
            "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout2d(p=0.25, inplace=False)\n",
            "  (dropout3): Dropout2d(p=0.5, inplace=False)\n",
            "  (dropout4): Dropout2d(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "損失関数・オプティマイザー・スケジュール"
      ],
      "metadata": {
        "id": "LV92NPqbDBzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
      ],
      "metadata": {
        "id": "7kTTfiPJvUcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **学習関数**"
      ],
      "metadata": {
        "id": "RjLGI0drDLCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_step = 0\n",
        "\n",
        "def train(epoch, writer):\n",
        "    model.train()\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\"\\n--- Epoch : %2d ---\" % epoch)\n",
        "    print(\"lr : %f\" % optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    steps = len(ds_train)//batch_size\n",
        "    for step, (images, labels) in enumerate(dataloader_train, 1):\n",
        "        global global_step\n",
        "        global_step += 1\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' % (epoch, epochs, step, steps, loss.item()))\n",
        "            writer.add_scalar('train/train_loss', loss.item() , global_step)\n"
      ],
      "metadata": {
        "id": "V3wVfEp1-SmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "評価関数"
      ],
      "metadata": {
        "id": "SCZMlUQZDPQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(epoch, writer):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for (images, labels) in dataloader_test:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    print(\"Val Acc : %.4f\" % (correct/total))\n",
        "    writer.add_scalar('eval/val_acc', correct*100/total, epoch)"
      ],
      "metadata": {
        "id": "ET6TTFmJkmmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "追加\n"
      ],
      "metadata": {
        "id": "i2bGmh5uDRto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnmZE7M-ltG7",
        "outputId": "20fb580c-154a-4268-b455-0191e33094e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **学習実行**"
      ],
      "metadata": {
        "id": "sUAU5LSXDbSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboardX import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    train(epoch, writer)\n",
        "    eval(epoch, writer)\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsS6VW1okp_F",
        "outputId": "46215677-9145-402a-eac9-142f170ac4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Epoch :  1 ---\n",
            "lr : 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/150], Step [100/500], Loss: 4.3823\n",
            "Epoch [1/150], Step [200/500], Loss: 4.1960\n",
            "Epoch [1/150], Step [300/500], Loss: 4.1547\n",
            "Epoch [1/150], Step [400/500], Loss: 4.0561\n",
            "Epoch [1/150], Step [500/500], Loss: 4.1552\n",
            "Val Acc : 0.1200\n",
            "\n",
            "--- Epoch :  2 ---\n",
            "lr : 0.001000\n",
            "Epoch [2/150], Step [100/500], Loss: 3.7239\n",
            "Epoch [2/150], Step [200/500], Loss: 3.8801\n",
            "Epoch [2/150], Step [300/500], Loss: 3.5869\n",
            "Epoch [2/150], Step [400/500], Loss: 3.4563\n",
            "Epoch [2/150], Step [500/500], Loss: 3.5150\n",
            "Val Acc : 0.1927\n",
            "\n",
            "--- Epoch :  3 ---\n",
            "lr : 0.001000\n",
            "Epoch [3/150], Step [100/500], Loss: 3.5483\n",
            "Epoch [3/150], Step [200/500], Loss: 3.4712\n",
            "Epoch [3/150], Step [300/500], Loss: 3.5441\n",
            "Epoch [3/150], Step [400/500], Loss: 3.3737\n",
            "Epoch [3/150], Step [500/500], Loss: 3.3220\n",
            "Val Acc : 0.2467\n",
            "\n",
            "--- Epoch :  4 ---\n",
            "lr : 0.001000\n",
            "Epoch [4/150], Step [100/500], Loss: 3.5068\n",
            "Epoch [4/150], Step [200/500], Loss: 3.1937\n",
            "Epoch [4/150], Step [300/500], Loss: 3.1034\n",
            "Epoch [4/150], Step [400/500], Loss: 3.2749\n",
            "Epoch [4/150], Step [500/500], Loss: 3.6198\n",
            "Val Acc : 0.2669\n",
            "\n",
            "--- Epoch :  5 ---\n",
            "lr : 0.001000\n",
            "Epoch [5/150], Step [100/500], Loss: 3.0820\n",
            "Epoch [5/150], Step [200/500], Loss: 3.0811\n",
            "Epoch [5/150], Step [300/500], Loss: 3.2895\n",
            "Epoch [5/150], Step [400/500], Loss: 3.2227\n",
            "Epoch [5/150], Step [500/500], Loss: 2.9484\n",
            "Val Acc : 0.2912\n",
            "\n",
            "--- Epoch :  6 ---\n",
            "lr : 0.001000\n",
            "Epoch [6/150], Step [100/500], Loss: 2.9499\n",
            "Epoch [6/150], Step [200/500], Loss: 3.3816\n",
            "Epoch [6/150], Step [300/500], Loss: 2.9580\n",
            "Epoch [6/150], Step [400/500], Loss: 2.9877\n",
            "Epoch [6/150], Step [500/500], Loss: 2.9125\n",
            "Val Acc : 0.3034\n",
            "\n",
            "--- Epoch :  7 ---\n",
            "lr : 0.001000\n",
            "Epoch [7/150], Step [100/500], Loss: 3.0627\n",
            "Epoch [7/150], Step [200/500], Loss: 2.7929\n",
            "Epoch [7/150], Step [300/500], Loss: 3.0825\n",
            "Epoch [7/150], Step [400/500], Loss: 2.8545\n",
            "Epoch [7/150], Step [500/500], Loss: 2.8874\n",
            "Val Acc : 0.3229\n",
            "\n",
            "--- Epoch :  8 ---\n",
            "lr : 0.001000\n",
            "Epoch [8/150], Step [100/500], Loss: 2.7338\n",
            "Epoch [8/150], Step [200/500], Loss: 3.1353\n",
            "Epoch [8/150], Step [300/500], Loss: 3.0648\n",
            "Epoch [8/150], Step [400/500], Loss: 3.1928\n",
            "Epoch [8/150], Step [500/500], Loss: 2.9563\n",
            "Val Acc : 0.3199\n",
            "\n",
            "--- Epoch :  9 ---\n",
            "lr : 0.001000\n",
            "Epoch [9/150], Step [100/500], Loss: 2.5925\n",
            "Epoch [9/150], Step [200/500], Loss: 2.6782\n",
            "Epoch [9/150], Step [300/500], Loss: 2.9945\n",
            "Epoch [9/150], Step [400/500], Loss: 2.6146\n",
            "Epoch [9/150], Step [500/500], Loss: 2.6210\n",
            "Val Acc : 0.3424\n",
            "\n",
            "--- Epoch : 10 ---\n",
            "lr : 0.000900\n",
            "Epoch [10/150], Step [100/500], Loss: 2.6186\n",
            "Epoch [10/150], Step [200/500], Loss: 2.7711\n",
            "Epoch [10/150], Step [300/500], Loss: 2.8935\n",
            "Epoch [10/150], Step [400/500], Loss: 2.6163\n",
            "Epoch [10/150], Step [500/500], Loss: 2.7166\n",
            "Val Acc : 0.3532\n",
            "\n",
            "--- Epoch : 11 ---\n",
            "lr : 0.000900\n",
            "Epoch [11/150], Step [100/500], Loss: 2.4632\n",
            "Epoch [11/150], Step [200/500], Loss: 2.6738\n",
            "Epoch [11/150], Step [300/500], Loss: 2.6618\n",
            "Epoch [11/150], Step [400/500], Loss: 2.8576\n",
            "Epoch [11/150], Step [500/500], Loss: 2.9123\n",
            "Val Acc : 0.3531\n",
            "\n",
            "--- Epoch : 12 ---\n",
            "lr : 0.000900\n",
            "Epoch [12/150], Step [100/500], Loss: 2.3750\n",
            "Epoch [12/150], Step [200/500], Loss: 2.7093\n",
            "Epoch [12/150], Step [300/500], Loss: 2.7188\n",
            "Epoch [12/150], Step [400/500], Loss: 2.8314\n",
            "Epoch [12/150], Step [500/500], Loss: 2.6470\n",
            "Val Acc : 0.3604\n",
            "\n",
            "--- Epoch : 13 ---\n",
            "lr : 0.000900\n",
            "Epoch [13/150], Step [100/500], Loss: 2.5598\n",
            "Epoch [13/150], Step [200/500], Loss: 2.9812\n",
            "Epoch [13/150], Step [300/500], Loss: 2.2980\n",
            "Epoch [13/150], Step [400/500], Loss: 2.5837\n",
            "Epoch [13/150], Step [500/500], Loss: 2.7923\n",
            "Val Acc : 0.3599\n",
            "\n",
            "--- Epoch : 14 ---\n",
            "lr : 0.000900\n",
            "Epoch [14/150], Step [100/500], Loss: 2.1417\n",
            "Epoch [14/150], Step [200/500], Loss: 2.3603\n",
            "Epoch [14/150], Step [300/500], Loss: 2.4978\n",
            "Epoch [14/150], Step [400/500], Loss: 2.4232\n",
            "Epoch [14/150], Step [500/500], Loss: 2.2555\n",
            "Val Acc : 0.3598\n",
            "\n",
            "--- Epoch : 15 ---\n",
            "lr : 0.000900\n",
            "Epoch [15/150], Step [100/500], Loss: 2.0506\n",
            "Epoch [15/150], Step [200/500], Loss: 2.4500\n",
            "Epoch [15/150], Step [300/500], Loss: 2.6140\n",
            "Epoch [15/150], Step [400/500], Loss: 2.3670\n",
            "Epoch [15/150], Step [500/500], Loss: 2.4668\n",
            "Val Acc : 0.3601\n",
            "\n",
            "--- Epoch : 16 ---\n",
            "lr : 0.000900\n",
            "Epoch [16/150], Step [100/500], Loss: 2.3228\n",
            "Epoch [16/150], Step [200/500], Loss: 2.4289\n",
            "Epoch [16/150], Step [300/500], Loss: 2.2328\n",
            "Epoch [16/150], Step [400/500], Loss: 2.1225\n",
            "Epoch [16/150], Step [500/500], Loss: 2.2567\n",
            "Val Acc : 0.3662\n",
            "\n",
            "--- Epoch : 17 ---\n",
            "lr : 0.000900\n",
            "Epoch [17/150], Step [100/500], Loss: 2.0689\n",
            "Epoch [17/150], Step [200/500], Loss: 2.3267\n",
            "Epoch [17/150], Step [300/500], Loss: 2.4344\n",
            "Epoch [17/150], Step [400/500], Loss: 2.2377\n",
            "Epoch [17/150], Step [500/500], Loss: 2.0078\n",
            "Val Acc : 0.3731\n",
            "\n",
            "--- Epoch : 18 ---\n",
            "lr : 0.000900\n",
            "Epoch [18/150], Step [100/500], Loss: 1.8929\n",
            "Epoch [18/150], Step [200/500], Loss: 2.2500\n",
            "Epoch [18/150], Step [300/500], Loss: 2.5322\n",
            "Epoch [18/150], Step [400/500], Loss: 2.6245\n",
            "Epoch [18/150], Step [500/500], Loss: 2.5762\n",
            "Val Acc : 0.3722\n",
            "\n",
            "--- Epoch : 19 ---\n",
            "lr : 0.000900\n",
            "Epoch [19/150], Step [100/500], Loss: 2.2675\n",
            "Epoch [19/150], Step [200/500], Loss: 2.2934\n",
            "Epoch [19/150], Step [300/500], Loss: 2.6286\n",
            "Epoch [19/150], Step [400/500], Loss: 1.9626\n",
            "Epoch [19/150], Step [500/500], Loss: 2.2033\n",
            "Val Acc : 0.3646\n",
            "\n",
            "--- Epoch : 20 ---\n",
            "lr : 0.000810\n",
            "Epoch [20/150], Step [100/500], Loss: 1.7105\n",
            "Epoch [20/150], Step [200/500], Loss: 1.9744\n",
            "Epoch [20/150], Step [300/500], Loss: 2.1596\n",
            "Epoch [20/150], Step [400/500], Loss: 2.0998\n",
            "Epoch [20/150], Step [500/500], Loss: 2.2818\n",
            "Val Acc : 0.3756\n",
            "\n",
            "--- Epoch : 21 ---\n",
            "lr : 0.000810\n",
            "Epoch [21/150], Step [100/500], Loss: 2.1819\n",
            "Epoch [21/150], Step [200/500], Loss: 2.2743\n",
            "Epoch [21/150], Step [300/500], Loss: 1.9109\n",
            "Epoch [21/150], Step [400/500], Loss: 1.9446\n",
            "Epoch [21/150], Step [500/500], Loss: 2.2132\n",
            "Val Acc : 0.3724\n",
            "\n",
            "--- Epoch : 22 ---\n",
            "lr : 0.000810\n",
            "Epoch [22/150], Step [100/500], Loss: 2.0204\n",
            "Epoch [22/150], Step [200/500], Loss: 1.9353\n",
            "Epoch [22/150], Step [300/500], Loss: 2.0894\n",
            "Epoch [22/150], Step [400/500], Loss: 2.3021\n",
            "Epoch [22/150], Step [500/500], Loss: 2.2708\n",
            "Val Acc : 0.3781\n",
            "\n",
            "--- Epoch : 23 ---\n",
            "lr : 0.000810\n",
            "Epoch [23/150], Step [100/500], Loss: 1.7994\n",
            "Epoch [23/150], Step [200/500], Loss: 2.1475\n",
            "Epoch [23/150], Step [300/500], Loss: 1.9749\n",
            "Epoch [23/150], Step [400/500], Loss: 1.9776\n",
            "Epoch [23/150], Step [500/500], Loss: 2.0712\n",
            "Val Acc : 0.3754\n",
            "\n",
            "--- Epoch : 24 ---\n",
            "lr : 0.000810\n",
            "Epoch [24/150], Step [100/500], Loss: 2.4150\n",
            "Epoch [24/150], Step [200/500], Loss: 1.7952\n",
            "Epoch [24/150], Step [300/500], Loss: 1.7506\n",
            "Epoch [24/150], Step [400/500], Loss: 2.1037\n",
            "Epoch [24/150], Step [500/500], Loss: 1.8018\n",
            "Val Acc : 0.3726\n",
            "\n",
            "--- Epoch : 25 ---\n",
            "lr : 0.000810\n",
            "Epoch [25/150], Step [100/500], Loss: 2.0187\n",
            "Epoch [25/150], Step [200/500], Loss: 1.8786\n",
            "Epoch [25/150], Step [300/500], Loss: 2.0494\n",
            "Epoch [25/150], Step [400/500], Loss: 1.8798\n",
            "Epoch [25/150], Step [500/500], Loss: 2.0008\n",
            "Val Acc : 0.3667\n",
            "\n",
            "--- Epoch : 26 ---\n",
            "lr : 0.000810\n",
            "Epoch [26/150], Step [100/500], Loss: 2.0272\n",
            "Epoch [26/150], Step [200/500], Loss: 1.8893\n",
            "Epoch [26/150], Step [300/500], Loss: 2.1704\n",
            "Epoch [26/150], Step [400/500], Loss: 1.8218\n",
            "Epoch [26/150], Step [500/500], Loss: 2.0017\n",
            "Val Acc : 0.3733\n",
            "\n",
            "--- Epoch : 27 ---\n",
            "lr : 0.000810\n",
            "Epoch [27/150], Step [100/500], Loss: 2.2049\n",
            "Epoch [27/150], Step [200/500], Loss: 2.1968\n",
            "Epoch [27/150], Step [300/500], Loss: 2.0651\n",
            "Epoch [27/150], Step [400/500], Loss: 1.9873\n",
            "Epoch [27/150], Step [500/500], Loss: 2.2576\n",
            "Val Acc : 0.3776\n",
            "\n",
            "--- Epoch : 28 ---\n",
            "lr : 0.000810\n",
            "Epoch [28/150], Step [100/500], Loss: 1.8118\n",
            "Epoch [28/150], Step [200/500], Loss: 1.9759\n",
            "Epoch [28/150], Step [300/500], Loss: 2.0491\n",
            "Epoch [28/150], Step [400/500], Loss: 1.9403\n",
            "Epoch [28/150], Step [500/500], Loss: 2.2312\n",
            "Val Acc : 0.3733\n",
            "\n",
            "--- Epoch : 29 ---\n",
            "lr : 0.000810\n",
            "Epoch [29/150], Step [100/500], Loss: 1.9189\n",
            "Epoch [29/150], Step [200/500], Loss: 1.8733\n",
            "Epoch [29/150], Step [300/500], Loss: 1.9807\n",
            "Epoch [29/150], Step [400/500], Loss: 1.9192\n",
            "Epoch [29/150], Step [500/500], Loss: 1.8717\n",
            "Val Acc : 0.3720\n",
            "\n",
            "--- Epoch : 30 ---\n",
            "lr : 0.000729\n",
            "Epoch [30/150], Step [100/500], Loss: 1.7978\n",
            "Epoch [30/150], Step [200/500], Loss: 1.8892\n",
            "Epoch [30/150], Step [300/500], Loss: 1.8644\n",
            "Epoch [30/150], Step [400/500], Loss: 1.8567\n",
            "Epoch [30/150], Step [500/500], Loss: 1.8918\n",
            "Val Acc : 0.3670\n",
            "\n",
            "--- Epoch : 31 ---\n",
            "lr : 0.000729\n",
            "Epoch [31/150], Step [100/500], Loss: 1.9543\n",
            "Epoch [31/150], Step [200/500], Loss: 1.7793\n",
            "Epoch [31/150], Step [300/500], Loss: 1.7679\n",
            "Epoch [31/150], Step [400/500], Loss: 2.3164\n",
            "Epoch [31/150], Step [500/500], Loss: 1.9568\n",
            "Val Acc : 0.3735\n",
            "\n",
            "--- Epoch : 32 ---\n",
            "lr : 0.000729\n",
            "Epoch [32/150], Step [100/500], Loss: 1.9484\n",
            "Epoch [32/150], Step [200/500], Loss: 2.0189\n",
            "Epoch [32/150], Step [300/500], Loss: 1.5410\n",
            "Epoch [32/150], Step [400/500], Loss: 1.6803\n",
            "Epoch [32/150], Step [500/500], Loss: 1.8643\n",
            "Val Acc : 0.3700\n",
            "\n",
            "--- Epoch : 33 ---\n",
            "lr : 0.000729\n",
            "Epoch [33/150], Step [100/500], Loss: 1.4923\n",
            "Epoch [33/150], Step [200/500], Loss: 1.6061\n",
            "Epoch [33/150], Step [300/500], Loss: 2.0582\n",
            "Epoch [33/150], Step [400/500], Loss: 2.2368\n",
            "Epoch [33/150], Step [500/500], Loss: 1.5431\n",
            "Val Acc : 0.3734\n",
            "\n",
            "--- Epoch : 34 ---\n",
            "lr : 0.000729\n",
            "Epoch [34/150], Step [100/500], Loss: 1.9189\n",
            "Epoch [34/150], Step [200/500], Loss: 1.7310\n",
            "Epoch [34/150], Step [300/500], Loss: 1.7758\n",
            "Epoch [34/150], Step [400/500], Loss: 1.6649\n",
            "Epoch [34/150], Step [500/500], Loss: 1.2989\n",
            "Val Acc : 0.3675\n",
            "\n",
            "--- Epoch : 35 ---\n",
            "lr : 0.000729\n",
            "Epoch [35/150], Step [100/500], Loss: 1.5633\n",
            "Epoch [35/150], Step [200/500], Loss: 1.5543\n",
            "Epoch [35/150], Step [300/500], Loss: 1.7326\n",
            "Epoch [35/150], Step [400/500], Loss: 1.7306\n",
            "Epoch [35/150], Step [500/500], Loss: 1.5071\n",
            "Val Acc : 0.3702\n",
            "\n",
            "--- Epoch : 36 ---\n",
            "lr : 0.000729\n",
            "Epoch [36/150], Step [100/500], Loss: 1.5892\n",
            "Epoch [36/150], Step [200/500], Loss: 1.5270\n",
            "Epoch [36/150], Step [300/500], Loss: 1.6278\n",
            "Epoch [36/150], Step [400/500], Loss: 1.8792\n",
            "Epoch [36/150], Step [500/500], Loss: 2.0918\n",
            "Val Acc : 0.3736\n",
            "\n",
            "--- Epoch : 37 ---\n",
            "lr : 0.000729\n",
            "Epoch [37/150], Step [100/500], Loss: 1.8271\n",
            "Epoch [37/150], Step [200/500], Loss: 1.3209\n",
            "Epoch [37/150], Step [300/500], Loss: 1.5920\n",
            "Epoch [37/150], Step [400/500], Loss: 1.6234\n",
            "Epoch [37/150], Step [500/500], Loss: 1.8303\n",
            "Val Acc : 0.3690\n",
            "\n",
            "--- Epoch : 38 ---\n",
            "lr : 0.000729\n",
            "Epoch [38/150], Step [100/500], Loss: 1.6873\n",
            "Epoch [38/150], Step [200/500], Loss: 1.8792\n",
            "Epoch [38/150], Step [300/500], Loss: 1.5277\n",
            "Epoch [38/150], Step [400/500], Loss: 1.7084\n",
            "Epoch [38/150], Step [500/500], Loss: 1.5736\n",
            "Val Acc : 0.3727\n",
            "\n",
            "--- Epoch : 39 ---\n",
            "lr : 0.000729\n",
            "Epoch [39/150], Step [100/500], Loss: 1.4091\n",
            "Epoch [39/150], Step [200/500], Loss: 1.4590\n",
            "Epoch [39/150], Step [300/500], Loss: 1.8407\n",
            "Epoch [39/150], Step [400/500], Loss: 1.5204\n",
            "Epoch [39/150], Step [500/500], Loss: 1.6457\n",
            "Val Acc : 0.3756\n",
            "\n",
            "--- Epoch : 40 ---\n",
            "lr : 0.000656\n",
            "Epoch [40/150], Step [100/500], Loss: 1.4705\n",
            "Epoch [40/150], Step [200/500], Loss: 1.8204\n",
            "Epoch [40/150], Step [300/500], Loss: 1.7318\n",
            "Epoch [40/150], Step [400/500], Loss: 1.7115\n",
            "Epoch [40/150], Step [500/500], Loss: 1.5010\n",
            "Val Acc : 0.3680\n",
            "\n",
            "--- Epoch : 41 ---\n",
            "lr : 0.000656\n",
            "Epoch [41/150], Step [100/500], Loss: 1.7414\n",
            "Epoch [41/150], Step [200/500], Loss: 1.2877\n",
            "Epoch [41/150], Step [300/500], Loss: 1.6093\n",
            "Epoch [41/150], Step [400/500], Loss: 1.5589\n",
            "Epoch [41/150], Step [500/500], Loss: 1.7530\n",
            "Val Acc : 0.3681\n",
            "\n",
            "--- Epoch : 42 ---\n",
            "lr : 0.000656\n",
            "Epoch [42/150], Step [100/500], Loss: 1.2794\n",
            "Epoch [42/150], Step [200/500], Loss: 1.6636\n",
            "Epoch [42/150], Step [300/500], Loss: 1.4719\n",
            "Epoch [42/150], Step [400/500], Loss: 1.4612\n",
            "Epoch [42/150], Step [500/500], Loss: 1.4613\n",
            "Val Acc : 0.3720\n",
            "\n",
            "--- Epoch : 43 ---\n",
            "lr : 0.000656\n",
            "Epoch [43/150], Step [100/500], Loss: 1.5568\n",
            "Epoch [43/150], Step [200/500], Loss: 1.5797\n",
            "Epoch [43/150], Step [300/500], Loss: 1.4360\n",
            "Epoch [43/150], Step [400/500], Loss: 1.7380\n",
            "Epoch [43/150], Step [500/500], Loss: 1.5635\n",
            "Val Acc : 0.3725\n",
            "\n",
            "--- Epoch : 44 ---\n",
            "lr : 0.000656\n",
            "Epoch [44/150], Step [100/500], Loss: 1.5295\n",
            "Epoch [44/150], Step [200/500], Loss: 1.6688\n",
            "Epoch [44/150], Step [300/500], Loss: 1.4493\n",
            "Epoch [44/150], Step [400/500], Loss: 1.8731\n",
            "Epoch [44/150], Step [500/500], Loss: 1.5462\n",
            "Val Acc : 0.3756\n",
            "\n",
            "--- Epoch : 45 ---\n",
            "lr : 0.000656\n",
            "Epoch [45/150], Step [100/500], Loss: 1.8607\n",
            "Epoch [45/150], Step [200/500], Loss: 1.3959\n",
            "Epoch [45/150], Step [300/500], Loss: 1.4209\n",
            "Epoch [45/150], Step [400/500], Loss: 1.5166\n",
            "Epoch [45/150], Step [500/500], Loss: 1.6283\n",
            "Val Acc : 0.3674\n",
            "\n",
            "--- Epoch : 46 ---\n",
            "lr : 0.000656\n",
            "Epoch [46/150], Step [100/500], Loss: 1.3892\n",
            "Epoch [46/150], Step [200/500], Loss: 1.5412\n",
            "Epoch [46/150], Step [300/500], Loss: 1.2314\n",
            "Epoch [46/150], Step [400/500], Loss: 1.7494\n",
            "Epoch [46/150], Step [500/500], Loss: 1.6553\n",
            "Val Acc : 0.3670\n",
            "\n",
            "--- Epoch : 47 ---\n",
            "lr : 0.000656\n",
            "Epoch [47/150], Step [100/500], Loss: 1.5979\n",
            "Epoch [47/150], Step [200/500], Loss: 1.6257\n",
            "Epoch [47/150], Step [300/500], Loss: 1.3675\n",
            "Epoch [47/150], Step [400/500], Loss: 1.4037\n",
            "Epoch [47/150], Step [500/500], Loss: 1.7943\n",
            "Val Acc : 0.3723\n",
            "\n",
            "--- Epoch : 48 ---\n",
            "lr : 0.000656\n",
            "Epoch [48/150], Step [100/500], Loss: 1.4900\n",
            "Epoch [48/150], Step [200/500], Loss: 1.8903\n",
            "Epoch [48/150], Step [300/500], Loss: 1.6909\n",
            "Epoch [48/150], Step [400/500], Loss: 1.8748\n",
            "Epoch [48/150], Step [500/500], Loss: 1.5400\n",
            "Val Acc : 0.3708\n",
            "\n",
            "--- Epoch : 49 ---\n",
            "lr : 0.000656\n",
            "Epoch [49/150], Step [100/500], Loss: 1.2327\n",
            "Epoch [49/150], Step [200/500], Loss: 1.6441\n",
            "Epoch [49/150], Step [300/500], Loss: 1.1547\n",
            "Epoch [49/150], Step [400/500], Loss: 1.4200\n",
            "Epoch [49/150], Step [500/500], Loss: 1.3087\n",
            "Val Acc : 0.3720\n",
            "\n",
            "--- Epoch : 50 ---\n",
            "lr : 0.000590\n",
            "Epoch [50/150], Step [100/500], Loss: 1.2750\n",
            "Epoch [50/150], Step [200/500], Loss: 1.2117\n",
            "Epoch [50/150], Step [300/500], Loss: 1.6161\n",
            "Epoch [50/150], Step [400/500], Loss: 1.4235\n",
            "Epoch [50/150], Step [500/500], Loss: 1.1088\n",
            "Val Acc : 0.3728\n",
            "\n",
            "--- Epoch : 51 ---\n",
            "lr : 0.000590\n",
            "Epoch [51/150], Step [100/500], Loss: 1.6052\n",
            "Epoch [51/150], Step [200/500], Loss: 1.1508\n",
            "Epoch [51/150], Step [300/500], Loss: 1.8908\n",
            "Epoch [51/150], Step [400/500], Loss: 1.5833\n",
            "Epoch [51/150], Step [500/500], Loss: 1.5027\n",
            "Val Acc : 0.3705\n",
            "\n",
            "--- Epoch : 52 ---\n",
            "lr : 0.000590\n",
            "Epoch [52/150], Step [100/500], Loss: 1.3831\n",
            "Epoch [52/150], Step [200/500], Loss: 1.2637\n",
            "Epoch [52/150], Step [300/500], Loss: 1.2007\n",
            "Epoch [52/150], Step [400/500], Loss: 1.5236\n",
            "Epoch [52/150], Step [500/500], Loss: 1.5714\n",
            "Val Acc : 0.3727\n",
            "\n",
            "--- Epoch : 53 ---\n",
            "lr : 0.000590\n",
            "Epoch [53/150], Step [100/500], Loss: 1.2914\n",
            "Epoch [53/150], Step [200/500], Loss: 1.6234\n",
            "Epoch [53/150], Step [300/500], Loss: 1.7643\n",
            "Epoch [53/150], Step [400/500], Loss: 1.5079\n",
            "Epoch [53/150], Step [500/500], Loss: 1.4498\n",
            "Val Acc : 0.3748\n",
            "\n",
            "--- Epoch : 54 ---\n",
            "lr : 0.000590\n",
            "Epoch [54/150], Step [100/500], Loss: 1.4338\n",
            "Epoch [54/150], Step [200/500], Loss: 1.3684\n",
            "Epoch [54/150], Step [300/500], Loss: 1.4114\n",
            "Epoch [54/150], Step [400/500], Loss: 1.2820\n",
            "Epoch [54/150], Step [500/500], Loss: 1.3029\n",
            "Val Acc : 0.3691\n",
            "\n",
            "--- Epoch : 55 ---\n",
            "lr : 0.000590\n",
            "Epoch [55/150], Step [100/500], Loss: 1.3776\n",
            "Epoch [55/150], Step [200/500], Loss: 1.2702\n",
            "Epoch [55/150], Step [300/500], Loss: 1.1529\n",
            "Epoch [55/150], Step [400/500], Loss: 1.6514\n",
            "Epoch [55/150], Step [500/500], Loss: 1.2922\n",
            "Val Acc : 0.3705\n",
            "\n",
            "--- Epoch : 56 ---\n",
            "lr : 0.000590\n",
            "Epoch [56/150], Step [100/500], Loss: 1.3364\n",
            "Epoch [56/150], Step [200/500], Loss: 1.3029\n",
            "Epoch [56/150], Step [300/500], Loss: 1.0510\n",
            "Epoch [56/150], Step [400/500], Loss: 1.1930\n",
            "Epoch [56/150], Step [500/500], Loss: 1.0842\n",
            "Val Acc : 0.3650\n",
            "\n",
            "--- Epoch : 57 ---\n",
            "lr : 0.000590\n",
            "Epoch [57/150], Step [100/500], Loss: 1.4411\n",
            "Epoch [57/150], Step [200/500], Loss: 1.4327\n",
            "Epoch [57/150], Step [300/500], Loss: 1.2801\n",
            "Epoch [57/150], Step [400/500], Loss: 1.3480\n",
            "Epoch [57/150], Step [500/500], Loss: 1.4271\n",
            "Val Acc : 0.3678\n",
            "\n",
            "--- Epoch : 58 ---\n",
            "lr : 0.000590\n",
            "Epoch [58/150], Step [100/500], Loss: 1.3928\n",
            "Epoch [58/150], Step [200/500], Loss: 1.6819\n",
            "Epoch [58/150], Step [300/500], Loss: 1.3336\n",
            "Epoch [58/150], Step [400/500], Loss: 1.4419\n",
            "Epoch [58/150], Step [500/500], Loss: 1.3695\n",
            "Val Acc : 0.3708\n",
            "\n",
            "--- Epoch : 59 ---\n",
            "lr : 0.000590\n",
            "Epoch [59/150], Step [100/500], Loss: 1.4196\n",
            "Epoch [59/150], Step [200/500], Loss: 1.5763\n",
            "Epoch [59/150], Step [300/500], Loss: 1.4000\n",
            "Epoch [59/150], Step [400/500], Loss: 1.4827\n",
            "Epoch [59/150], Step [500/500], Loss: 1.4225\n",
            "Val Acc : 0.3667\n",
            "\n",
            "--- Epoch : 60 ---\n",
            "lr : 0.000531\n",
            "Epoch [60/150], Step [100/500], Loss: 1.0710\n",
            "Epoch [60/150], Step [200/500], Loss: 1.4617\n",
            "Epoch [60/150], Step [300/500], Loss: 1.3561\n",
            "Epoch [60/150], Step [400/500], Loss: 1.3153\n",
            "Epoch [60/150], Step [500/500], Loss: 1.3574\n",
            "Val Acc : 0.3678\n",
            "\n",
            "--- Epoch : 61 ---\n",
            "lr : 0.000531\n",
            "Epoch [61/150], Step [100/500], Loss: 1.0975\n",
            "Epoch [61/150], Step [200/500], Loss: 1.1679\n",
            "Epoch [61/150], Step [300/500], Loss: 1.4375\n",
            "Epoch [61/150], Step [400/500], Loss: 1.6139\n",
            "Epoch [61/150], Step [500/500], Loss: 1.2593\n",
            "Val Acc : 0.3653\n",
            "\n",
            "--- Epoch : 62 ---\n",
            "lr : 0.000531\n",
            "Epoch [62/150], Step [100/500], Loss: 1.5377\n",
            "Epoch [62/150], Step [200/500], Loss: 1.2615\n",
            "Epoch [62/150], Step [300/500], Loss: 1.3529\n",
            "Epoch [62/150], Step [400/500], Loss: 1.0746\n",
            "Epoch [62/150], Step [500/500], Loss: 1.4522\n",
            "Val Acc : 0.3729\n",
            "\n",
            "--- Epoch : 63 ---\n",
            "lr : 0.000531\n",
            "Epoch [63/150], Step [100/500], Loss: 1.1611\n",
            "Epoch [63/150], Step [200/500], Loss: 1.3211\n",
            "Epoch [63/150], Step [300/500], Loss: 1.2091\n",
            "Epoch [63/150], Step [400/500], Loss: 1.5171\n",
            "Epoch [63/150], Step [500/500], Loss: 1.1748\n",
            "Val Acc : 0.3715\n",
            "\n",
            "--- Epoch : 64 ---\n",
            "lr : 0.000531\n",
            "Epoch [64/150], Step [100/500], Loss: 1.4664\n",
            "Epoch [64/150], Step [200/500], Loss: 1.1186\n",
            "Epoch [64/150], Step [300/500], Loss: 1.0873\n",
            "Epoch [64/150], Step [400/500], Loss: 1.1744\n",
            "Epoch [64/150], Step [500/500], Loss: 0.9768\n",
            "Val Acc : 0.3687\n",
            "\n",
            "--- Epoch : 65 ---\n",
            "lr : 0.000531\n",
            "Epoch [65/150], Step [100/500], Loss: 1.0353\n",
            "Epoch [65/150], Step [200/500], Loss: 1.1742\n",
            "Epoch [65/150], Step [300/500], Loss: 1.3168\n",
            "Epoch [65/150], Step [400/500], Loss: 1.0521\n",
            "Epoch [65/150], Step [500/500], Loss: 1.2074\n",
            "Val Acc : 0.3706\n",
            "\n",
            "--- Epoch : 66 ---\n",
            "lr : 0.000531\n",
            "Epoch [66/150], Step [100/500], Loss: 1.3001\n",
            "Epoch [66/150], Step [200/500], Loss: 1.3329\n",
            "Epoch [66/150], Step [300/500], Loss: 1.0382\n",
            "Epoch [66/150], Step [400/500], Loss: 1.1497\n",
            "Epoch [66/150], Step [500/500], Loss: 1.1637\n",
            "Val Acc : 0.3727\n",
            "\n",
            "--- Epoch : 67 ---\n",
            "lr : 0.000531\n",
            "Epoch [67/150], Step [100/500], Loss: 0.9249\n",
            "Epoch [67/150], Step [200/500], Loss: 1.0840\n",
            "Epoch [67/150], Step [300/500], Loss: 1.3962\n",
            "Epoch [67/150], Step [400/500], Loss: 1.0319\n",
            "Epoch [67/150], Step [500/500], Loss: 1.2300\n",
            "Val Acc : 0.3703\n",
            "\n",
            "--- Epoch : 68 ---\n",
            "lr : 0.000531\n",
            "Epoch [68/150], Step [100/500], Loss: 1.3656\n",
            "Epoch [68/150], Step [200/500], Loss: 1.3782\n",
            "Epoch [68/150], Step [300/500], Loss: 1.1474\n",
            "Epoch [68/150], Step [400/500], Loss: 1.3104\n",
            "Epoch [68/150], Step [500/500], Loss: 1.3031\n",
            "Val Acc : 0.3764\n",
            "\n",
            "--- Epoch : 69 ---\n",
            "lr : 0.000531\n",
            "Epoch [69/150], Step [100/500], Loss: 1.4210\n",
            "Epoch [69/150], Step [200/500], Loss: 1.1530\n",
            "Epoch [69/150], Step [300/500], Loss: 1.3112\n",
            "Epoch [69/150], Step [400/500], Loss: 1.2534\n",
            "Epoch [69/150], Step [500/500], Loss: 1.1926\n",
            "Val Acc : 0.3727\n",
            "\n",
            "--- Epoch : 70 ---\n",
            "lr : 0.000478\n",
            "Epoch [70/150], Step [100/500], Loss: 1.2492\n",
            "Epoch [70/150], Step [200/500], Loss: 1.0573\n",
            "Epoch [70/150], Step [300/500], Loss: 1.2070\n",
            "Epoch [70/150], Step [400/500], Loss: 1.0427\n",
            "Epoch [70/150], Step [500/500], Loss: 1.1670\n",
            "Val Acc : 0.3668\n",
            "\n",
            "--- Epoch : 71 ---\n",
            "lr : 0.000478\n",
            "Epoch [71/150], Step [100/500], Loss: 1.2043\n",
            "Epoch [71/150], Step [200/500], Loss: 1.1232\n",
            "Epoch [71/150], Step [300/500], Loss: 0.9639\n",
            "Epoch [71/150], Step [400/500], Loss: 1.3695\n",
            "Epoch [71/150], Step [500/500], Loss: 1.0440\n",
            "Val Acc : 0.3706\n",
            "\n",
            "--- Epoch : 72 ---\n",
            "lr : 0.000478\n",
            "Epoch [72/150], Step [100/500], Loss: 1.1683\n",
            "Epoch [72/150], Step [200/500], Loss: 1.1736\n",
            "Epoch [72/150], Step [300/500], Loss: 1.0998\n",
            "Epoch [72/150], Step [400/500], Loss: 1.3615\n",
            "Epoch [72/150], Step [500/500], Loss: 1.1362\n",
            "Val Acc : 0.3666\n",
            "\n",
            "--- Epoch : 73 ---\n",
            "lr : 0.000478\n",
            "Epoch [73/150], Step [100/500], Loss: 0.9197\n",
            "Epoch [73/150], Step [200/500], Loss: 0.8983\n",
            "Epoch [73/150], Step [300/500], Loss: 1.1270\n",
            "Epoch [73/150], Step [400/500], Loss: 1.0444\n",
            "Epoch [73/150], Step [500/500], Loss: 1.0613\n",
            "Val Acc : 0.3661\n",
            "\n",
            "--- Epoch : 74 ---\n",
            "lr : 0.000478\n",
            "Epoch [74/150], Step [100/500], Loss: 0.9485\n",
            "Epoch [74/150], Step [200/500], Loss: 1.0889\n",
            "Epoch [74/150], Step [300/500], Loss: 1.3158\n",
            "Epoch [74/150], Step [400/500], Loss: 1.2006\n",
            "Epoch [74/150], Step [500/500], Loss: 0.9702\n",
            "Val Acc : 0.3683\n",
            "\n",
            "--- Epoch : 75 ---\n",
            "lr : 0.000478\n",
            "Epoch [75/150], Step [100/500], Loss: 1.0280\n",
            "Epoch [75/150], Step [200/500], Loss: 0.9327\n",
            "Epoch [75/150], Step [300/500], Loss: 1.3859\n",
            "Epoch [75/150], Step [400/500], Loss: 1.0437\n",
            "Epoch [75/150], Step [500/500], Loss: 1.0381\n",
            "Val Acc : 0.3689\n",
            "\n",
            "--- Epoch : 76 ---\n",
            "lr : 0.000478\n",
            "Epoch [76/150], Step [100/500], Loss: 1.3138\n",
            "Epoch [76/150], Step [200/500], Loss: 1.1102\n",
            "Epoch [76/150], Step [300/500], Loss: 1.2471\n",
            "Epoch [76/150], Step [400/500], Loss: 1.1643\n",
            "Epoch [76/150], Step [500/500], Loss: 1.0839\n",
            "Val Acc : 0.3682\n",
            "\n",
            "--- Epoch : 77 ---\n",
            "lr : 0.000478\n",
            "Epoch [77/150], Step [100/500], Loss: 0.9573\n",
            "Epoch [77/150], Step [200/500], Loss: 1.2504\n",
            "Epoch [77/150], Step [300/500], Loss: 1.2121\n",
            "Epoch [77/150], Step [400/500], Loss: 1.1478\n",
            "Epoch [77/150], Step [500/500], Loss: 0.9214\n",
            "Val Acc : 0.3645\n",
            "\n",
            "--- Epoch : 78 ---\n",
            "lr : 0.000478\n",
            "Epoch [78/150], Step [100/500], Loss: 0.8194\n",
            "Epoch [78/150], Step [200/500], Loss: 1.1924\n",
            "Epoch [78/150], Step [300/500], Loss: 1.0162\n",
            "Epoch [78/150], Step [400/500], Loss: 0.9686\n",
            "Epoch [78/150], Step [500/500], Loss: 1.0970\n",
            "Val Acc : 0.3758\n",
            "\n",
            "--- Epoch : 79 ---\n",
            "lr : 0.000478\n",
            "Epoch [79/150], Step [100/500], Loss: 1.0582\n",
            "Epoch [79/150], Step [200/500], Loss: 0.9029\n",
            "Epoch [79/150], Step [300/500], Loss: 1.2428\n",
            "Epoch [79/150], Step [400/500], Loss: 0.9307\n",
            "Epoch [79/150], Step [500/500], Loss: 1.1922\n",
            "Val Acc : 0.3721\n",
            "\n",
            "--- Epoch : 80 ---\n",
            "lr : 0.000430\n",
            "Epoch [80/150], Step [100/500], Loss: 0.9284\n",
            "Epoch [80/150], Step [200/500], Loss: 0.8688\n",
            "Epoch [80/150], Step [300/500], Loss: 1.0288\n",
            "Epoch [80/150], Step [400/500], Loss: 0.9598\n",
            "Epoch [80/150], Step [500/500], Loss: 1.1539\n",
            "Val Acc : 0.3696\n",
            "\n",
            "--- Epoch : 81 ---\n",
            "lr : 0.000430\n",
            "Epoch [81/150], Step [100/500], Loss: 1.0548\n",
            "Epoch [81/150], Step [200/500], Loss: 0.9660\n",
            "Epoch [81/150], Step [300/500], Loss: 0.9604\n",
            "Epoch [81/150], Step [400/500], Loss: 1.0136\n",
            "Epoch [81/150], Step [500/500], Loss: 0.8552\n",
            "Val Acc : 0.3697\n",
            "\n",
            "--- Epoch : 82 ---\n",
            "lr : 0.000430\n",
            "Epoch [82/150], Step [100/500], Loss: 0.9142\n",
            "Epoch [82/150], Step [200/500], Loss: 0.9807\n",
            "Epoch [82/150], Step [300/500], Loss: 1.0968\n",
            "Epoch [82/150], Step [400/500], Loss: 1.0383\n",
            "Epoch [82/150], Step [500/500], Loss: 1.0585\n",
            "Val Acc : 0.3653\n",
            "\n",
            "--- Epoch : 83 ---\n",
            "lr : 0.000430\n",
            "Epoch [83/150], Step [100/500], Loss: 1.3126\n",
            "Epoch [83/150], Step [200/500], Loss: 1.2665\n",
            "Epoch [83/150], Step [300/500], Loss: 0.7128\n",
            "Epoch [83/150], Step [400/500], Loss: 1.2735\n",
            "Epoch [83/150], Step [500/500], Loss: 1.0444\n",
            "Val Acc : 0.3659\n",
            "\n",
            "--- Epoch : 84 ---\n",
            "lr : 0.000430\n",
            "Epoch [84/150], Step [100/500], Loss: 0.9099\n",
            "Epoch [84/150], Step [200/500], Loss: 0.9604\n",
            "Epoch [84/150], Step [300/500], Loss: 0.8007\n",
            "Epoch [84/150], Step [400/500], Loss: 1.0952\n",
            "Epoch [84/150], Step [500/500], Loss: 1.0900\n",
            "Val Acc : 0.3715\n",
            "\n",
            "--- Epoch : 85 ---\n",
            "lr : 0.000430\n",
            "Epoch [85/150], Step [100/500], Loss: 1.0782\n",
            "Epoch [85/150], Step [200/500], Loss: 0.8036\n",
            "Epoch [85/150], Step [300/500], Loss: 1.0747\n",
            "Epoch [85/150], Step [400/500], Loss: 1.1579\n",
            "Epoch [85/150], Step [500/500], Loss: 1.1094\n",
            "Val Acc : 0.3747\n",
            "\n",
            "--- Epoch : 86 ---\n",
            "lr : 0.000430\n",
            "Epoch [86/150], Step [100/500], Loss: 0.9882\n",
            "Epoch [86/150], Step [200/500], Loss: 0.7282\n",
            "Epoch [86/150], Step [300/500], Loss: 1.0273\n",
            "Epoch [86/150], Step [400/500], Loss: 0.9331\n",
            "Epoch [86/150], Step [500/500], Loss: 1.1850\n",
            "Val Acc : 0.3720\n",
            "\n",
            "--- Epoch : 87 ---\n",
            "lr : 0.000430\n",
            "Epoch [87/150], Step [100/500], Loss: 0.9601\n",
            "Epoch [87/150], Step [200/500], Loss: 1.1656\n",
            "Epoch [87/150], Step [300/500], Loss: 1.0112\n",
            "Epoch [87/150], Step [400/500], Loss: 1.1375\n",
            "Epoch [87/150], Step [500/500], Loss: 1.0838\n",
            "Val Acc : 0.3631\n",
            "\n",
            "--- Epoch : 88 ---\n",
            "lr : 0.000430\n",
            "Epoch [88/150], Step [100/500], Loss: 1.0186\n",
            "Epoch [88/150], Step [200/500], Loss: 0.7583\n",
            "Epoch [88/150], Step [300/500], Loss: 1.0291\n",
            "Epoch [88/150], Step [400/500], Loss: 1.1142\n",
            "Epoch [88/150], Step [500/500], Loss: 1.0066\n",
            "Val Acc : 0.3769\n",
            "\n",
            "--- Epoch : 89 ---\n",
            "lr : 0.000430\n",
            "Epoch [89/150], Step [100/500], Loss: 1.1227\n",
            "Epoch [89/150], Step [200/500], Loss: 1.2726\n",
            "Epoch [89/150], Step [300/500], Loss: 1.1191\n",
            "Epoch [89/150], Step [400/500], Loss: 0.8927\n",
            "Epoch [89/150], Step [500/500], Loss: 1.2030\n",
            "Val Acc : 0.3705\n",
            "\n",
            "--- Epoch : 90 ---\n",
            "lr : 0.000387\n",
            "Epoch [90/150], Step [100/500], Loss: 1.0835\n",
            "Epoch [90/150], Step [200/500], Loss: 0.8700\n",
            "Epoch [90/150], Step [300/500], Loss: 1.4318\n",
            "Epoch [90/150], Step [400/500], Loss: 1.1332\n",
            "Epoch [90/150], Step [500/500], Loss: 0.8382\n",
            "Val Acc : 0.3688\n",
            "\n",
            "--- Epoch : 91 ---\n",
            "lr : 0.000387\n",
            "Epoch [91/150], Step [100/500], Loss: 1.1596\n",
            "Epoch [91/150], Step [200/500], Loss: 1.3191\n",
            "Epoch [91/150], Step [300/500], Loss: 1.0025\n",
            "Epoch [91/150], Step [400/500], Loss: 0.8364\n",
            "Epoch [91/150], Step [500/500], Loss: 1.0563\n",
            "Val Acc : 0.3726\n",
            "\n",
            "--- Epoch : 92 ---\n",
            "lr : 0.000387\n",
            "Epoch [92/150], Step [100/500], Loss: 0.9427\n",
            "Epoch [92/150], Step [200/500], Loss: 0.8059\n",
            "Epoch [92/150], Step [300/500], Loss: 0.9246\n",
            "Epoch [92/150], Step [400/500], Loss: 1.1376\n",
            "Epoch [92/150], Step [500/500], Loss: 1.2274\n",
            "Val Acc : 0.3704\n",
            "\n",
            "--- Epoch : 93 ---\n",
            "lr : 0.000387\n",
            "Epoch [93/150], Step [100/500], Loss: 0.9890\n",
            "Epoch [93/150], Step [200/500], Loss: 0.9813\n",
            "Epoch [93/150], Step [300/500], Loss: 1.0366\n",
            "Epoch [93/150], Step [400/500], Loss: 1.1101\n",
            "Epoch [93/150], Step [500/500], Loss: 1.1360\n",
            "Val Acc : 0.3697\n",
            "\n",
            "--- Epoch : 94 ---\n",
            "lr : 0.000387\n",
            "Epoch [94/150], Step [100/500], Loss: 0.9943\n",
            "Epoch [94/150], Step [200/500], Loss: 0.8299\n",
            "Epoch [94/150], Step [300/500], Loss: 1.0728\n",
            "Epoch [94/150], Step [400/500], Loss: 1.0714\n",
            "Epoch [94/150], Step [500/500], Loss: 1.0182\n",
            "Val Acc : 0.3712\n",
            "\n",
            "--- Epoch : 95 ---\n",
            "lr : 0.000387\n",
            "Epoch [95/150], Step [100/500], Loss: 0.7874\n",
            "Epoch [95/150], Step [200/500], Loss: 1.0301\n",
            "Epoch [95/150], Step [300/500], Loss: 0.9762\n",
            "Epoch [95/150], Step [400/500], Loss: 0.7718\n",
            "Epoch [95/150], Step [500/500], Loss: 0.8406\n",
            "Val Acc : 0.3729\n",
            "\n",
            "--- Epoch : 96 ---\n",
            "lr : 0.000387\n",
            "Epoch [96/150], Step [100/500], Loss: 0.7520\n",
            "Epoch [96/150], Step [200/500], Loss: 0.8273\n",
            "Epoch [96/150], Step [300/500], Loss: 0.8434\n",
            "Epoch [96/150], Step [400/500], Loss: 1.0314\n",
            "Epoch [96/150], Step [500/500], Loss: 1.2295\n",
            "Val Acc : 0.3688\n",
            "\n",
            "--- Epoch : 97 ---\n",
            "lr : 0.000387\n",
            "Epoch [97/150], Step [100/500], Loss: 1.1315\n",
            "Epoch [97/150], Step [200/500], Loss: 0.8621\n",
            "Epoch [97/150], Step [300/500], Loss: 0.8802\n",
            "Epoch [97/150], Step [400/500], Loss: 1.1762\n",
            "Epoch [97/150], Step [500/500], Loss: 1.1778\n",
            "Val Acc : 0.3711\n",
            "\n",
            "--- Epoch : 98 ---\n",
            "lr : 0.000387\n",
            "Epoch [98/150], Step [100/500], Loss: 0.9901\n",
            "Epoch [98/150], Step [200/500], Loss: 1.0301\n",
            "Epoch [98/150], Step [300/500], Loss: 1.0598\n",
            "Epoch [98/150], Step [400/500], Loss: 0.7829\n",
            "Epoch [98/150], Step [500/500], Loss: 1.0272\n",
            "Val Acc : 0.3690\n",
            "\n",
            "--- Epoch : 99 ---\n",
            "lr : 0.000387\n",
            "Epoch [99/150], Step [100/500], Loss: 1.0131\n",
            "Epoch [99/150], Step [200/500], Loss: 1.0561\n",
            "Epoch [99/150], Step [300/500], Loss: 0.9959\n",
            "Epoch [99/150], Step [400/500], Loss: 1.1840\n",
            "Epoch [99/150], Step [500/500], Loss: 1.1736\n",
            "Val Acc : 0.3730\n",
            "\n",
            "--- Epoch : 100 ---\n",
            "lr : 0.000349\n",
            "Epoch [100/150], Step [100/500], Loss: 1.0336\n",
            "Epoch [100/150], Step [200/500], Loss: 1.0811\n",
            "Epoch [100/150], Step [300/500], Loss: 1.2785\n",
            "Epoch [100/150], Step [400/500], Loss: 0.8462\n",
            "Epoch [100/150], Step [500/500], Loss: 1.1401\n",
            "Val Acc : 0.3709\n",
            "\n",
            "--- Epoch : 101 ---\n",
            "lr : 0.000349\n",
            "Epoch [101/150], Step [100/500], Loss: 1.0218\n",
            "Epoch [101/150], Step [200/500], Loss: 0.7662\n",
            "Epoch [101/150], Step [300/500], Loss: 1.1561\n",
            "Epoch [101/150], Step [400/500], Loss: 1.2197\n",
            "Epoch [101/150], Step [500/500], Loss: 0.9607\n",
            "Val Acc : 0.3703\n",
            "\n",
            "--- Epoch : 102 ---\n",
            "lr : 0.000349\n",
            "Epoch [102/150], Step [100/500], Loss: 0.7414\n",
            "Epoch [102/150], Step [200/500], Loss: 0.9377\n",
            "Epoch [102/150], Step [300/500], Loss: 0.9304\n",
            "Epoch [102/150], Step [400/500], Loss: 1.0277\n",
            "Epoch [102/150], Step [500/500], Loss: 0.7783\n",
            "Val Acc : 0.3703\n",
            "\n",
            "--- Epoch : 103 ---\n",
            "lr : 0.000349\n",
            "Epoch [103/150], Step [100/500], Loss: 0.9486\n",
            "Epoch [103/150], Step [200/500], Loss: 0.9537\n",
            "Epoch [103/150], Step [300/500], Loss: 0.8750\n",
            "Epoch [103/150], Step [400/500], Loss: 1.1074\n",
            "Epoch [103/150], Step [500/500], Loss: 0.8091\n",
            "Val Acc : 0.3665\n",
            "\n",
            "--- Epoch : 104 ---\n",
            "lr : 0.000349\n",
            "Epoch [104/150], Step [100/500], Loss: 1.0567\n",
            "Epoch [104/150], Step [200/500], Loss: 0.8834\n",
            "Epoch [104/150], Step [300/500], Loss: 0.9186\n",
            "Epoch [104/150], Step [400/500], Loss: 1.0481\n",
            "Epoch [104/150], Step [500/500], Loss: 1.0379\n",
            "Val Acc : 0.3659\n",
            "\n",
            "--- Epoch : 105 ---\n",
            "lr : 0.000349\n",
            "Epoch [105/150], Step [100/500], Loss: 0.8533\n",
            "Epoch [105/150], Step [200/500], Loss: 1.0198\n",
            "Epoch [105/150], Step [300/500], Loss: 1.2337\n",
            "Epoch [105/150], Step [400/500], Loss: 0.8830\n",
            "Epoch [105/150], Step [500/500], Loss: 0.9414\n",
            "Val Acc : 0.3706\n",
            "\n",
            "--- Epoch : 106 ---\n",
            "lr : 0.000349\n",
            "Epoch [106/150], Step [100/500], Loss: 1.0048\n",
            "Epoch [106/150], Step [200/500], Loss: 0.7422\n",
            "Epoch [106/150], Step [300/500], Loss: 0.9765\n",
            "Epoch [106/150], Step [400/500], Loss: 1.1961\n",
            "Epoch [106/150], Step [500/500], Loss: 0.9744\n",
            "Val Acc : 0.3695\n",
            "\n",
            "--- Epoch : 107 ---\n",
            "lr : 0.000349\n",
            "Epoch [107/150], Step [100/500], Loss: 1.1190\n",
            "Epoch [107/150], Step [200/500], Loss: 1.0368\n",
            "Epoch [107/150], Step [300/500], Loss: 0.9566\n",
            "Epoch [107/150], Step [400/500], Loss: 1.1161\n",
            "Epoch [107/150], Step [500/500], Loss: 0.7751\n",
            "Val Acc : 0.3696\n",
            "\n",
            "--- Epoch : 108 ---\n",
            "lr : 0.000349\n",
            "Epoch [108/150], Step [100/500], Loss: 0.7499\n",
            "Epoch [108/150], Step [200/500], Loss: 1.0265\n",
            "Epoch [108/150], Step [300/500], Loss: 1.0028\n",
            "Epoch [108/150], Step [400/500], Loss: 0.6612\n",
            "Epoch [108/150], Step [500/500], Loss: 1.2088\n",
            "Val Acc : 0.3712\n",
            "\n",
            "--- Epoch : 109 ---\n",
            "lr : 0.000349\n",
            "Epoch [109/150], Step [100/500], Loss: 0.7177\n",
            "Epoch [109/150], Step [200/500], Loss: 0.9099\n",
            "Epoch [109/150], Step [300/500], Loss: 1.0447\n",
            "Epoch [109/150], Step [400/500], Loss: 0.6994\n",
            "Epoch [109/150], Step [500/500], Loss: 1.0346\n",
            "Val Acc : 0.3699\n",
            "\n",
            "--- Epoch : 110 ---\n",
            "lr : 0.000314\n",
            "Epoch [110/150], Step [100/500], Loss: 0.7607\n",
            "Epoch [110/150], Step [200/500], Loss: 1.0977\n",
            "Epoch [110/150], Step [300/500], Loss: 0.7112\n",
            "Epoch [110/150], Step [400/500], Loss: 0.9815\n",
            "Epoch [110/150], Step [500/500], Loss: 1.0144\n",
            "Val Acc : 0.3719\n",
            "\n",
            "--- Epoch : 111 ---\n",
            "lr : 0.000314\n",
            "Epoch [111/150], Step [100/500], Loss: 0.8381\n",
            "Epoch [111/150], Step [200/500], Loss: 0.7071\n",
            "Epoch [111/150], Step [300/500], Loss: 0.9640\n",
            "Epoch [111/150], Step [400/500], Loss: 0.8522\n",
            "Epoch [111/150], Step [500/500], Loss: 0.8369\n",
            "Val Acc : 0.3716\n",
            "\n",
            "--- Epoch : 112 ---\n",
            "lr : 0.000314\n",
            "Epoch [112/150], Step [100/500], Loss: 1.0062\n",
            "Epoch [112/150], Step [200/500], Loss: 0.8824\n",
            "Epoch [112/150], Step [300/500], Loss: 0.8403\n",
            "Epoch [112/150], Step [400/500], Loss: 0.9821\n",
            "Epoch [112/150], Step [500/500], Loss: 0.7209\n",
            "Val Acc : 0.3701\n",
            "\n",
            "--- Epoch : 113 ---\n",
            "lr : 0.000314\n",
            "Epoch [113/150], Step [100/500], Loss: 0.7105\n",
            "Epoch [113/150], Step [200/500], Loss: 0.7109\n",
            "Epoch [113/150], Step [300/500], Loss: 1.0667\n",
            "Epoch [113/150], Step [400/500], Loss: 0.7173\n",
            "Epoch [113/150], Step [500/500], Loss: 0.9494\n",
            "Val Acc : 0.3675\n",
            "\n",
            "--- Epoch : 114 ---\n",
            "lr : 0.000314\n",
            "Epoch [114/150], Step [100/500], Loss: 0.8029\n",
            "Epoch [114/150], Step [200/500], Loss: 0.9177\n",
            "Epoch [114/150], Step [300/500], Loss: 0.8018\n",
            "Epoch [114/150], Step [400/500], Loss: 1.1256\n",
            "Epoch [114/150], Step [500/500], Loss: 0.7005\n",
            "Val Acc : 0.3704\n",
            "\n",
            "--- Epoch : 115 ---\n",
            "lr : 0.000314\n",
            "Epoch [115/150], Step [100/500], Loss: 0.8207\n",
            "Epoch [115/150], Step [200/500], Loss: 1.1773\n",
            "Epoch [115/150], Step [300/500], Loss: 1.0195\n",
            "Epoch [115/150], Step [400/500], Loss: 0.9872\n",
            "Epoch [115/150], Step [500/500], Loss: 1.0995\n",
            "Val Acc : 0.3685\n",
            "\n",
            "--- Epoch : 116 ---\n",
            "lr : 0.000314\n",
            "Epoch [116/150], Step [100/500], Loss: 0.9067\n",
            "Epoch [116/150], Step [200/500], Loss: 0.8022\n",
            "Epoch [116/150], Step [300/500], Loss: 1.0774\n",
            "Epoch [116/150], Step [400/500], Loss: 1.1908\n",
            "Epoch [116/150], Step [500/500], Loss: 1.0268\n",
            "Val Acc : 0.3690\n",
            "\n",
            "--- Epoch : 117 ---\n",
            "lr : 0.000314\n",
            "Epoch [117/150], Step [100/500], Loss: 0.8540\n",
            "Epoch [117/150], Step [200/500], Loss: 0.7132\n",
            "Epoch [117/150], Step [300/500], Loss: 1.0517\n",
            "Epoch [117/150], Step [400/500], Loss: 1.0881\n",
            "Epoch [117/150], Step [500/500], Loss: 0.7315\n",
            "Val Acc : 0.3675\n",
            "\n",
            "--- Epoch : 118 ---\n",
            "lr : 0.000314\n",
            "Epoch [118/150], Step [100/500], Loss: 0.8326\n",
            "Epoch [118/150], Step [200/500], Loss: 0.7961\n",
            "Epoch [118/150], Step [300/500], Loss: 1.0974\n",
            "Epoch [118/150], Step [400/500], Loss: 0.8642\n",
            "Epoch [118/150], Step [500/500], Loss: 1.1581\n",
            "Val Acc : 0.3671\n",
            "\n",
            "--- Epoch : 119 ---\n",
            "lr : 0.000314\n",
            "Epoch [119/150], Step [100/500], Loss: 0.8617\n",
            "Epoch [119/150], Step [200/500], Loss: 0.9830\n",
            "Epoch [119/150], Step [300/500], Loss: 0.6056\n",
            "Epoch [119/150], Step [400/500], Loss: 0.7346\n",
            "Epoch [119/150], Step [500/500], Loss: 0.9483\n",
            "Val Acc : 0.3663\n",
            "\n",
            "--- Epoch : 120 ---\n",
            "lr : 0.000282\n",
            "Epoch [120/150], Step [100/500], Loss: 0.7640\n",
            "Epoch [120/150], Step [200/500], Loss: 0.8827\n",
            "Epoch [120/150], Step [300/500], Loss: 1.0668\n",
            "Epoch [120/150], Step [400/500], Loss: 0.9797\n",
            "Epoch [120/150], Step [500/500], Loss: 0.9311\n",
            "Val Acc : 0.3658\n",
            "\n",
            "--- Epoch : 121 ---\n",
            "lr : 0.000282\n",
            "Epoch [121/150], Step [100/500], Loss: 0.8798\n",
            "Epoch [121/150], Step [200/500], Loss: 0.6630\n",
            "Epoch [121/150], Step [300/500], Loss: 0.8418\n",
            "Epoch [121/150], Step [400/500], Loss: 0.8730\n",
            "Epoch [121/150], Step [500/500], Loss: 0.7615\n",
            "Val Acc : 0.3672\n",
            "\n",
            "--- Epoch : 122 ---\n",
            "lr : 0.000282\n",
            "Epoch [122/150], Step [100/500], Loss: 0.9695\n",
            "Epoch [122/150], Step [200/500], Loss: 0.8326\n",
            "Epoch [122/150], Step [300/500], Loss: 0.7118\n",
            "Epoch [122/150], Step [400/500], Loss: 0.9158\n",
            "Epoch [122/150], Step [500/500], Loss: 1.2505\n",
            "Val Acc : 0.3671\n",
            "\n",
            "--- Epoch : 123 ---\n",
            "lr : 0.000282\n",
            "Epoch [123/150], Step [100/500], Loss: 0.6459\n",
            "Epoch [123/150], Step [200/500], Loss: 0.6400\n",
            "Epoch [123/150], Step [300/500], Loss: 0.8131\n",
            "Epoch [123/150], Step [400/500], Loss: 0.8476\n",
            "Epoch [123/150], Step [500/500], Loss: 0.8032\n",
            "Val Acc : 0.3687\n",
            "\n",
            "--- Epoch : 124 ---\n",
            "lr : 0.000282\n",
            "Epoch [124/150], Step [100/500], Loss: 0.8089\n",
            "Epoch [124/150], Step [200/500], Loss: 0.7586\n",
            "Epoch [124/150], Step [300/500], Loss: 1.1124\n",
            "Epoch [124/150], Step [400/500], Loss: 0.7834\n",
            "Epoch [124/150], Step [500/500], Loss: 0.8604\n",
            "Val Acc : 0.3692\n",
            "\n",
            "--- Epoch : 125 ---\n",
            "lr : 0.000282\n",
            "Epoch [125/150], Step [100/500], Loss: 0.9208\n",
            "Epoch [125/150], Step [200/500], Loss: 0.6602\n",
            "Epoch [125/150], Step [300/500], Loss: 0.5903\n",
            "Epoch [125/150], Step [400/500], Loss: 0.6767\n",
            "Epoch [125/150], Step [500/500], Loss: 0.8091\n",
            "Val Acc : 0.3661\n",
            "\n",
            "--- Epoch : 126 ---\n",
            "lr : 0.000282\n",
            "Epoch [126/150], Step [100/500], Loss: 0.7982\n",
            "Epoch [126/150], Step [200/500], Loss: 0.6054\n",
            "Epoch [126/150], Step [300/500], Loss: 0.8069\n",
            "Epoch [126/150], Step [400/500], Loss: 0.6504\n",
            "Epoch [126/150], Step [500/500], Loss: 0.8091\n",
            "Val Acc : 0.3707\n",
            "\n",
            "--- Epoch : 127 ---\n",
            "lr : 0.000282\n",
            "Epoch [127/150], Step [100/500], Loss: 0.5923\n",
            "Epoch [127/150], Step [200/500], Loss: 0.7956\n",
            "Epoch [127/150], Step [300/500], Loss: 0.7922\n",
            "Epoch [127/150], Step [400/500], Loss: 0.6367\n",
            "Epoch [127/150], Step [500/500], Loss: 0.7271\n",
            "Val Acc : 0.3713\n",
            "\n",
            "--- Epoch : 128 ---\n",
            "lr : 0.000282\n",
            "Epoch [128/150], Step [100/500], Loss: 0.7255\n",
            "Epoch [128/150], Step [200/500], Loss: 0.7176\n",
            "Epoch [128/150], Step [300/500], Loss: 0.7853\n",
            "Epoch [128/150], Step [400/500], Loss: 0.9523\n",
            "Epoch [128/150], Step [500/500], Loss: 0.8009\n",
            "Val Acc : 0.3675\n",
            "\n",
            "--- Epoch : 129 ---\n",
            "lr : 0.000282\n",
            "Epoch [129/150], Step [100/500], Loss: 0.7429\n",
            "Epoch [129/150], Step [200/500], Loss: 0.8105\n",
            "Epoch [129/150], Step [300/500], Loss: 0.9990\n",
            "Epoch [129/150], Step [400/500], Loss: 0.7977\n",
            "Epoch [129/150], Step [500/500], Loss: 1.0409\n",
            "Val Acc : 0.3657\n",
            "\n",
            "--- Epoch : 130 ---\n",
            "lr : 0.000254\n",
            "Epoch [130/150], Step [100/500], Loss: 0.8481\n",
            "Epoch [130/150], Step [200/500], Loss: 0.7834\n",
            "Epoch [130/150], Step [300/500], Loss: 0.8858\n",
            "Epoch [130/150], Step [400/500], Loss: 1.0268\n",
            "Epoch [130/150], Step [500/500], Loss: 0.8558\n",
            "Val Acc : 0.3709\n",
            "\n",
            "--- Epoch : 131 ---\n",
            "lr : 0.000254\n",
            "Epoch [131/150], Step [100/500], Loss: 0.7473\n",
            "Epoch [131/150], Step [200/500], Loss: 0.8315\n",
            "Epoch [131/150], Step [300/500], Loss: 0.6567\n",
            "Epoch [131/150], Step [400/500], Loss: 0.5158\n",
            "Epoch [131/150], Step [500/500], Loss: 0.8313\n",
            "Val Acc : 0.3719\n",
            "\n",
            "--- Epoch : 132 ---\n",
            "lr : 0.000254\n",
            "Epoch [132/150], Step [100/500], Loss: 0.6237\n",
            "Epoch [132/150], Step [200/500], Loss: 0.8049\n",
            "Epoch [132/150], Step [300/500], Loss: 0.6585\n",
            "Epoch [132/150], Step [400/500], Loss: 0.7850\n",
            "Epoch [132/150], Step [500/500], Loss: 0.8759\n",
            "Val Acc : 0.3706\n",
            "\n",
            "--- Epoch : 133 ---\n",
            "lr : 0.000254\n",
            "Epoch [133/150], Step [100/500], Loss: 0.6192\n",
            "Epoch [133/150], Step [200/500], Loss: 0.5465\n",
            "Epoch [133/150], Step [300/500], Loss: 0.9185\n",
            "Epoch [133/150], Step [400/500], Loss: 0.8387\n",
            "Epoch [133/150], Step [500/500], Loss: 1.0325\n",
            "Val Acc : 0.3689\n",
            "\n",
            "--- Epoch : 134 ---\n",
            "lr : 0.000254\n",
            "Epoch [134/150], Step [100/500], Loss: 0.7192\n",
            "Epoch [134/150], Step [200/500], Loss: 0.8372\n",
            "Epoch [134/150], Step [300/500], Loss: 0.7016\n",
            "Epoch [134/150], Step [400/500], Loss: 0.9413\n",
            "Epoch [134/150], Step [500/500], Loss: 0.7036\n",
            "Val Acc : 0.3677\n",
            "\n",
            "--- Epoch : 135 ---\n",
            "lr : 0.000254\n",
            "Epoch [135/150], Step [100/500], Loss: 0.8688\n",
            "Epoch [135/150], Step [200/500], Loss: 0.7110\n",
            "Epoch [135/150], Step [300/500], Loss: 0.6135\n",
            "Epoch [135/150], Step [400/500], Loss: 0.8091\n",
            "Epoch [135/150], Step [500/500], Loss: 0.5751\n",
            "Val Acc : 0.3710\n",
            "\n",
            "--- Epoch : 136 ---\n",
            "lr : 0.000254\n",
            "Epoch [136/150], Step [100/500], Loss: 0.7577\n",
            "Epoch [136/150], Step [200/500], Loss: 0.7975\n",
            "Epoch [136/150], Step [300/500], Loss: 1.2983\n",
            "Epoch [136/150], Step [400/500], Loss: 0.6932\n",
            "Epoch [136/150], Step [500/500], Loss: 0.8835\n",
            "Val Acc : 0.3722\n",
            "\n",
            "--- Epoch : 137 ---\n",
            "lr : 0.000254\n",
            "Epoch [137/150], Step [100/500], Loss: 0.6219\n",
            "Epoch [137/150], Step [200/500], Loss: 0.8727\n",
            "Epoch [137/150], Step [300/500], Loss: 0.9450\n",
            "Epoch [137/150], Step [400/500], Loss: 1.0499\n",
            "Epoch [137/150], Step [500/500], Loss: 0.7808\n",
            "Val Acc : 0.3707\n",
            "\n",
            "--- Epoch : 138 ---\n",
            "lr : 0.000254\n",
            "Epoch [138/150], Step [100/500], Loss: 0.6634\n",
            "Epoch [138/150], Step [200/500], Loss: 0.8613\n",
            "Epoch [138/150], Step [300/500], Loss: 1.0738\n",
            "Epoch [138/150], Step [400/500], Loss: 0.8826\n",
            "Epoch [138/150], Step [500/500], Loss: 0.6074\n",
            "Val Acc : 0.3709\n",
            "\n",
            "--- Epoch : 139 ---\n",
            "lr : 0.000254\n",
            "Epoch [139/150], Step [100/500], Loss: 0.7904\n",
            "Epoch [139/150], Step [200/500], Loss: 1.1054\n",
            "Epoch [139/150], Step [300/500], Loss: 0.7546\n",
            "Epoch [139/150], Step [400/500], Loss: 0.7593\n",
            "Epoch [139/150], Step [500/500], Loss: 0.8372\n",
            "Val Acc : 0.3715\n",
            "\n",
            "--- Epoch : 140 ---\n",
            "lr : 0.000229\n",
            "Epoch [140/150], Step [100/500], Loss: 0.7859\n",
            "Epoch [140/150], Step [200/500], Loss: 0.9021\n",
            "Epoch [140/150], Step [300/500], Loss: 0.9736\n",
            "Epoch [140/150], Step [400/500], Loss: 0.7505\n",
            "Epoch [140/150], Step [500/500], Loss: 0.6945\n",
            "Val Acc : 0.3714\n",
            "\n",
            "--- Epoch : 141 ---\n",
            "lr : 0.000229\n",
            "Epoch [141/150], Step [100/500], Loss: 0.9716\n",
            "Epoch [141/150], Step [200/500], Loss: 0.7704\n",
            "Epoch [141/150], Step [300/500], Loss: 0.6938\n",
            "Epoch [141/150], Step [400/500], Loss: 0.6923\n",
            "Epoch [141/150], Step [500/500], Loss: 0.8377\n",
            "Val Acc : 0.3666\n",
            "\n",
            "--- Epoch : 142 ---\n",
            "lr : 0.000229\n",
            "Epoch [142/150], Step [100/500], Loss: 0.9218\n",
            "Epoch [142/150], Step [200/500], Loss: 0.7995\n",
            "Epoch [142/150], Step [300/500], Loss: 0.6958\n",
            "Epoch [142/150], Step [400/500], Loss: 0.4591\n",
            "Epoch [142/150], Step [500/500], Loss: 1.1966\n",
            "Val Acc : 0.3712\n",
            "\n",
            "--- Epoch : 143 ---\n",
            "lr : 0.000229\n",
            "Epoch [143/150], Step [100/500], Loss: 0.8336\n",
            "Epoch [143/150], Step [200/500], Loss: 0.7103\n",
            "Epoch [143/150], Step [300/500], Loss: 0.7871\n",
            "Epoch [143/150], Step [400/500], Loss: 0.5649\n",
            "Epoch [143/150], Step [500/500], Loss: 0.8459\n",
            "Val Acc : 0.3720\n",
            "\n",
            "--- Epoch : 144 ---\n",
            "lr : 0.000229\n",
            "Epoch [144/150], Step [100/500], Loss: 0.8718\n",
            "Epoch [144/150], Step [200/500], Loss: 0.6195\n",
            "Epoch [144/150], Step [300/500], Loss: 0.7340\n",
            "Epoch [144/150], Step [400/500], Loss: 0.8910\n",
            "Epoch [144/150], Step [500/500], Loss: 0.6943\n",
            "Val Acc : 0.3697\n",
            "\n",
            "--- Epoch : 145 ---\n",
            "lr : 0.000229\n",
            "Epoch [145/150], Step [100/500], Loss: 0.9218\n",
            "Epoch [145/150], Step [200/500], Loss: 0.6575\n",
            "Epoch [145/150], Step [300/500], Loss: 0.8364\n",
            "Epoch [145/150], Step [400/500], Loss: 0.9765\n",
            "Epoch [145/150], Step [500/500], Loss: 0.8277\n",
            "Val Acc : 0.3719\n",
            "\n",
            "--- Epoch : 146 ---\n",
            "lr : 0.000229\n",
            "Epoch [146/150], Step [100/500], Loss: 0.7368\n",
            "Epoch [146/150], Step [200/500], Loss: 0.6315\n",
            "Epoch [146/150], Step [300/500], Loss: 0.7555\n",
            "Epoch [146/150], Step [400/500], Loss: 0.8502\n",
            "Epoch [146/150], Step [500/500], Loss: 0.9690\n",
            "Val Acc : 0.3715\n",
            "\n",
            "--- Epoch : 147 ---\n",
            "lr : 0.000229\n",
            "Epoch [147/150], Step [100/500], Loss: 0.4935\n",
            "Epoch [147/150], Step [200/500], Loss: 0.7405\n",
            "Epoch [147/150], Step [300/500], Loss: 0.6766\n",
            "Epoch [147/150], Step [400/500], Loss: 0.9879\n",
            "Epoch [147/150], Step [500/500], Loss: 0.8368\n",
            "Val Acc : 0.3741\n",
            "\n",
            "--- Epoch : 148 ---\n",
            "lr : 0.000229\n",
            "Epoch [148/150], Step [100/500], Loss: 0.6031\n",
            "Epoch [148/150], Step [200/500], Loss: 0.8673\n",
            "Epoch [148/150], Step [300/500], Loss: 0.6465\n",
            "Epoch [148/150], Step [400/500], Loss: 0.7725\n",
            "Epoch [148/150], Step [500/500], Loss: 0.6391\n",
            "Val Acc : 0.3720\n",
            "\n",
            "--- Epoch : 149 ---\n",
            "lr : 0.000229\n",
            "Epoch [149/150], Step [100/500], Loss: 0.9771\n",
            "Epoch [149/150], Step [200/500], Loss: 0.8620\n",
            "Epoch [149/150], Step [300/500], Loss: 0.7277\n",
            "Epoch [149/150], Step [400/500], Loss: 0.6919\n",
            "Epoch [149/150], Step [500/500], Loss: 0.8106\n",
            "Val Acc : 0.3728\n",
            "\n",
            "--- Epoch : 150 ---\n",
            "lr : 0.000206\n",
            "Epoch [150/150], Step [100/500], Loss: 0.9544\n",
            "Epoch [150/150], Step [200/500], Loss: 0.6327\n",
            "Epoch [150/150], Step [300/500], Loss: 1.0115\n",
            "Epoch [150/150], Step [400/500], Loss: 0.5039\n",
            "Epoch [150/150], Step [500/500], Loss: 0.7869\n",
            "Val Acc : 0.3719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **保存**"
      ],
      "metadata": {
        "id": "zVR92mwKDkyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_cifar100.pkl')"
      ],
      "metadata": {
        "id": "LvTvoqFPmLZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# state_dict()の表示\n",
        "for key in model.state_dict():\n",
        "    print(key, \": \", model.state_dict()[key].size())\n",
        "\n",
        "# 保存\n",
        "torch.save(model.state_dict(), \"model_cnn100.pth\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a143BRMTufwA",
        "outputId": "e36eea3d-d7cb-48ad-a79e-653e0cdd9fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv11.weight :  torch.Size([32, 3, 3, 3])\n",
            "conv11.bias :  torch.Size([32])\n",
            "conv12.weight :  torch.Size([32, 32, 3, 3])\n",
            "conv12.bias :  torch.Size([32])\n",
            "conv21.weight :  torch.Size([64, 32, 3, 3])\n",
            "conv21.bias :  torch.Size([64])\n",
            "conv22.weight :  torch.Size([64, 64, 3, 3])\n",
            "conv22.bias :  torch.Size([64])\n",
            "fc1.weight :  torch.Size([1024, 4096])\n",
            "fc1.bias :  torch.Size([1024])\n",
            "fc2.weight :  torch.Size([512, 1024])\n",
            "fc2.bias :  torch.Size([512])\n",
            "fc3.weight :  torch.Size([100, 512])\n",
            "fc3.bias :  torch.Size([100])\n"
          ]
        }
      ]
    }
  ]
}